<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Automated Mode</title>
  <style>
    /* Prevent horizontal overflow */
    html, body {
      overflow-x: hidden;
    }
    /* Full viewport height and styling */
    body {
      margin: 0;
      padding: 0;
      background-color: black;
      color: #ccff00;
      font-family: sans-serif;
      display: flex;
      flex-direction: column;
      height: 100vh;
    }
    #topSection {
      flex: 1;
      display: flex;
      flex-direction: column;
      justify-content: center;
      align-items: center;
    }
    #bottomSection {
      display: flex;
      justify-content: center;
      align-items: flex-end;
      margin-bottom: 2em;
    }
    button {
      font-weight: bold;
      text-transform: uppercase;
      border-radius: 1.25em;
      cursor: pointer;
      transition: background-color 0.3s, color 0.3s;
      border: 0.125em solid #ccff00;
    }
    #controlButton {
      background-color: #ccff00;
      color: black;
      width: clamp(15em, 50vw, 45em);
      font-size: clamp(2em, 8vw, 5em);
      padding: 1em;
      margin: 0.5rem;
    }
    #controlButton:hover {
      background-color: #ccff00;
      color: black;
    }
    #backButton {
      background-color: black;
      color: #ccff00;
      width: clamp(14em, 40vw, 35em);
      font-size: clamp(1.8em, 7vw, 4em);
      padding: 0.8em;
      margin: 0.5rem;
    }
    #backButton:hover {
      background-color: #ccff00;
      color: black;
    }
    /* Hide video and canvas used for browser capture (no longer needed) */
    #video, #canvas {
      display: none;
    }
    /* Visible preview canvas for captured image */
    #capturePreview {
      width: 200px;
      height: auto;
      margin-bottom: 1em;
      border: 0.125em solid #ccff00;
    }
    /* Generated text styling: big font */
    #resultText {
      font-size: 2em;
      text-align: center;
      margin-top: 1em;
      max-width: 90%;
    }
  </style>
</head>
<body>
  <!-- Top section: preview canvas, START button, and generated text output -->
  <div id="topSection">
    <canvas id="capturePreview"></canvas>
    <button id="controlButton">START</button>
    <p id="resultText"></p>
  </div>

  <!-- Bottom section: GO BACK button -->
  <div id="bottomSection">
    <button id="backButton">GO BACK</button>
  </div>

  <script>
    const controlButton = document.getElementById('controlButton');
    const backButton = document.getElementById('backButton');
    const capturePreview = document.getElementById('capturePreview');
    const resultTextElement = document.getElementById('resultText');

    let isRunning = false;
    let currentAbortController = null;
    let currentSource = null;

    // Function to resume AudioContext (if needed)
    const audioContext = new (window.AudioContext || window.webkitAudioContext)();
    async function resumeAudioContext() {
      if (audioContext.state === 'suspended') {
        await audioContext.resume();
      }
    }

    // playTTS: Uses the /api/tts endpoint to get the MP3 URL,
    // fetches the audio as an ArrayBuffer, decodes it,
    // plays it via an AudioBufferSourceNode, and when audio ends, triggers captureAndProcess.
    async function playTTS(text) {
      try {
        await resumeAudioContext();
        const response = await fetch('/api/tts', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ text })
        });
        const data = await response.json();
        if (data.error) {
          console.error("TTS error:", data.error);
          return;
        }
        const audioResponse = await fetch(data.url);
        const arrayBuffer = await audioResponse.arrayBuffer();
        const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
        const source = audioContext.createBufferSource();
        source.buffer = audioBuffer;
        source.connect(audioContext.destination);
        source.onended = () => {
          if (isRunning) {
            captureAndProcess();
          }
        };
        currentSource = source;
        source.start(0);
      } catch (error) {
        console.error("Error in playTTS:", error);
      }
    }

    // captureAndProcess: Calls the /api/capture endpoint, displays the captured image,
    // then sends the image to /api/automated to generate a description.
    async function captureAndProcess() {
      try {
        resultTextElement.textContent = "Capturing image...";
        // Call the backend capture endpoint.
        const captureResponse = await fetch('/api/capture');
        const captureData = await captureResponse.json();
        if (captureData.error) {
          resultTextElement.textContent = "Error capturing image.";
          return;
        }
        const base64Image = captureData.image_base64;

        // Display the captured image on the preview canvas.
        const image = new Image();
        image.src = "data:image/jpeg;base64," + base64Image;
        image.onload = function() {
          capturePreview.width = 200;
          capturePreview.height = (image.height / image.width) * 200;
          const previewCtx = capturePreview.getContext('2d');
          previewCtx.drawImage(image, 0, 0, capturePreview.width, capturePreview.height);
        };

        // Now upload the captured image to the automated endpoint.
        resultTextElement.textContent = "Generating description...";
        const response = await fetch('/api/automated', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ image_base64: base64Image })
        });
        if (!response.ok) throw new Error("API error");

        let resultText = "";
        const reader = response.body.getReader();
        const decoder = new TextDecoder();
        while (true) {
          if (!isRunning) return;
          const { value, done } = await reader.read();
          if (done) break;
          const chunk = decoder.decode(value, { stream: true });
          chunk.split("\n").forEach(line => {
            if (line.startsWith("data: ")) {
              const jsonStr = line.slice(6).trim();
              if (jsonStr) {
                resultText += JSON.parse(jsonStr).text;
                resultTextElement.textContent = resultText;
              }
            }
          });
        }

        if (isRunning && resultText) {
          playTTS(resultText);
        }
      } catch (error) {
        console.error(error);
        if (isRunning) {
          playTTS("I'm sorry, I couldn't process the environment.");
        }
      }
    }

    // Toggle the process when the START/STOP button is clicked.
    controlButton.addEventListener('click', async () => {
      await resumeAudioContext();
      if (!isRunning) {
        isRunning = true;
        controlButton.textContent = "STOP";
        captureAndProcess();
      } else {
        isRunning = false;
        controlButton.textContent = "START";
        if (currentAbortController) {
          currentAbortController.abort();
        }
        if (currentSource) {
          currentSource.stop();
          currentSource = null;
        }
      }
    });

    // GO BACK button: Stop all processes and navigate home.
    backButton.addEventListener('click', () => {
      if (isRunning) {
        isRunning = false;
        controlButton.textContent = "START";
        if (currentAbortController) {
          currentAbortController.abort();
        }
        if (currentSource) {
          currentSource.stop();
          currentSource = null;
        }
      }
      window.location.href = "/";
    });
  </script>
</body>
</html>

